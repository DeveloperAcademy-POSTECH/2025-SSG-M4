기존 대형 언어 모델의 파라미터는 그대로 두고, 소규모 신경망 모듈을 추가로 삽입해 
특정 작업이나 도메인에 맞게 효율적으로 미세조정(fine-tuning)할 수 있게 해주는 고급 기능입니다.

## 왜 Adapter를 사용하는가?
- 효율적 미세조정: Adapter의 작은 모듈만 훈련,교체하면 된다.
- 빠른 훈련, 낮은 비용: 훈련 속도가 빠르고 데이터, 메모리, 저장 공간 소모가 적다.
- 온디바이스 특화: 여러 Adapter를 필요할 때마다 동적으로 로드/교체할 수 있다.
- 원본 모델의 능력 보존: Adapter만 바꾸기 때문에 원래의 범용적 능력은 유지된다.

## Adapter 훈련 과정
## 기술적 구조
## 실무 활용 및 장점

***추후 딥다이브 예정***